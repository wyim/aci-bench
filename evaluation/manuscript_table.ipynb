{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "name_pairs={\n",
    "\n",
    "\"taskB_organizer\":\"clinicalnlp_taskB_test1\",\n",
    "\"taskC_organizer\":\"clinicalnlp_taskC_test2\",\n",
    "\"clef_organizer\":\"clef_taskC_test3\",\n",
    "\"chatgpt_run2\":\"ChatGPT_\",\n",
    "\"chatgpt_run2\":\"ChatGPT_\",\n",
    "\"davinci2_run2\":\"Text-Davinci-002_\",\n",
    "\"davinci3_run2\":\"Text-Davinci-003_\",\n",
    "\"gpt4_run2\":\"GPT-4_\",\n",
    "\"clinicalnlp_taskB_test1\":\"test1\",\n",
    "\"clinicalnlp_taskC_test2\":\"test2\",\n",
    "\"clef_taskC_test3\":\"test3\",\n",
    "\"_1024\":\"\",\n",
    "\"_gl1024\":\"\",\n",
    "\n",
    "}\n",
    "\n",
    "files=glob(\"../baselines/predictions/*.csv\")\n",
    "files+=glob(\"../results/*.json\")\n",
    "for file in files:\n",
    "    new_name=file+\"\"\n",
    "    for key in name_pairs:\n",
    "        new_name=new_name.replace(key,name_pairs[key])\n",
    "    os.rename(file,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for file in glob(\"/home/velvinfu/code/aci-demo-benchmark-private-main/results/*.csv.json\"):\n",
    "    result=json.loads(open(file).read())[\"ALL\"][\"rouge1\"]\n",
    "    if result>0.99:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "files=glob(\"../results/*.csv.json\")\n",
    "#testsets=[\"clinicalnlp_taskB_test1\",\"clinicalnlp_taskC_test2\",\"clef_taskC_test3\"] #\"train\",\"valid\",\n",
    "testsets=[\"test1\",\"test2\",\"test3\"]\n",
    "# test 1\n",
    "for dataset in testsets:\n",
    "    model_map={\n",
    "        \"longest spearker turn\":'../results/longest_speaker_turn_{}.csv.json'.format(dataset),\n",
    "        \"longest doctor turn\":'../results/longest_doctor_turn_{}.csv.json'.format(dataset),\n",
    "        \"12 speaker turns\":'../results/12_speaker_turns_{}.csv.json'.format(dataset),\n",
    "        \"12 doctor turns\": '../results/12_doctor_turns_{}.csv.json'.format(dataset),\n",
    "        \"transcript\":\"../results/transcript_{}.csv.json\".format(dataset),\n",
    "        \"train_UMLS\":\"../results/UMLS_similarity_{}.csv.json\".format(dataset),\n",
    "        \"train_sent\":'../results/spacy_similarity_{}.csv.json'.format(dataset),\n",
    "    }\n",
    "\n",
    "    #read_data\n",
    "    for model in [\"BART_large\",\"bart-large-xsum-samsum\",\"BioBART\",\"LED\",\"LED_pubmed\",\n",
    "                  \"Text-Davinci-002\",\"Text-Davinci-003\",\"ChatGPT\",\"GPT-4\"]:\n",
    "        outfile='../results/{}_{}_full_ori.csv.json'.format(model,dataset)\n",
    "        #open_ai models\n",
    "        if not os.path.isfile(outfile):\n",
    "            outfile='../results/{}{}_.csv.json'.format(dataset,model) \n",
    "        if outfile not in files:\n",
    "            outfile=[file for file in files if \"{}_{}_full_ori\".format(model,dataset) in file]\n",
    "            outfile.sort()\n",
    "            outfile=outfile[-1] if outfile else \"\"\n",
    "        key=model.replace(\"_1024\",\"\").replace(\"bart-large\",\"BART\").replace(\"_large\",\"\").replace(\"-xsum-samsum\",\"+FT_$_{\\mathrm{SAMSum}}$\").replace(\"_pubmed\",\"+FT$_{\\mathrm{PubMed}}$\")\n",
    "        #baseline\n",
    "        model_map[key]=outfile\n",
    "\n",
    "        if model in [\"BART_large\",\"bart-large-xsum-samsum\",\"BioBART\",\"LED\",\"LED_pubmed\"]:\n",
    "            #Division\n",
    "            outfile=[file for file in files if model in file and \"{}_{}_ori_SOAP_combined\".format(model,dataset) in file]\n",
    "            model_map[key+\" (Division)\"]=outfile[-1] if outfile else \"\"\n",
    "        \n",
    "    #map\n",
    "    with open(\"../tables/{}.csv\".format(dataset),\"w\") as f:\n",
    "        for result_type in [\"ALL\", \"division-subjective\",\"division-objective_exam\",\n",
    "                            \"division-objective_results\",\"division-assessment_and_plan\"]:\n",
    "            f.write(\"\\n\\n\"+result_type+\"\\n\")\n",
    "            headers=['Model','ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BERTScore', 'BLEURT','Fact',\"average\"]\n",
    "            f.write(\",\".join(headers)+\"\\n\")\n",
    "            for key in model_map:\n",
    "                if key in [\"BART\",\"LED\"]:\n",
    "                    f.write(\"{}-based\\n\".format(key))\n",
    "                elif key==\"longest spearker turn\":\n",
    "                    f.write(\"Transcript-based\\n\")\n",
    "                elif key==\"train_UMLS\":\n",
    "                    f.write(\"Retrieval-based\\n\")\n",
    "                elif key==\"Text-Davinci-002\":\n",
    "                    f.write(\"OpenAI (wo FT)\\n\")\n",
    "                row=[key]\n",
    "                if os.path.isfile(model_map[key]):\n",
    "                    result=json.loads(open(model_map[key]).read())[result_type]\n",
    "                    for metric in ['rouge1', 'rouge2', 'rougeLsum', 'bertscore-f1', 'bleurt','umls']:\n",
    "                        row.append(float(result[metric]))\n",
    "                    row.append(((sum(row[1:4])/3+sum(row[4:7])))/4)\n",
    "                    row=[row[0]]+[\"{:.2f}\".format(round(r*100,2)) for r in row[1:]]\n",
    "                else:\n",
    "                    row=row+[\"NA\"]*7\n",
    "                f.write(\",\".join(row)+\"\\n\")\n",
    "            # f.write(\"OpenAI (wo FT)\\n\")\n",
    "            # f.write(\"\\n\".join([\"Text-Davinci-00{} [p{}]\".format(t1,t2) for t1 in [2,3] for t2 in [1,2]]))\n",
    "            # f.write(\"\\nChatGPT (gpt-3.5-turbo) [p1]\\nChatGPT (gpt-3.5-turbo) [p2]\\n\")\n",
    "        # print('\\nTexttable Table:')\n",
    "        # print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/bart-large-xsum-samsum_test1_ori_SOAP_combined.json'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(model_map[key]).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/velvinfu/code/clef2023-internal/results/BART_large_valid_full_ori_prediction_valid_full.csv.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'../results/{}_{}_full_ori_prediction_{}_full.csv.json'.format(model,dataset,dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/bart-large-xsum-samsum_ablation_test1_virtscribe_asr_train_ori_division_combined.csv.json\n",
      "../results/bart-large-xsum-samsum_ablation_test1_virtscribe_humantrans_train_ori_division_combined.csv.json\n",
      "../results/bart-large-xsum-samsum_ablation_test2_virtscribe_asr_train_ori_division_combined.csv.json\n",
      "../results/bart-large-xsum-samsum_ablation_test2_virtscribe_humantrans_train_ori_division_combined.csv.json\n",
      "../results/bart-large-xsum-samsum_ablation_test3_virtscribe_asr_train_ori_division_combined.csv.json\n",
      "../results/bart-large-xsum-samsum_ablation_test3_virtscribe_humantrans_train_ori_division_combined.csv.json\n"
     ]
    }
   ],
   "source": [
    "##ablation study\n",
    "\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "files=glob(\"../results/*.json\")\n",
    "\n",
    "all_models=[\"aci_asr\",\"aci_asrcorr\"] #[\"virtscribe_asr\", \"virtscribe_humantrans\"]\n",
    "train_set=\"on_aci_asrcorr\" #[\"ori\",\"on_virtscribe_asr\"]\n",
    "\n",
    "all_models=[\"virtscribe_asr\", \"virtscribe_humantrans\"]\n",
    "train_set=\"on_virtscribe_asr\"\n",
    "\n",
    "for models in [all_models]:\n",
    "    # test 1\n",
    "    with open(\"../tables/{}.csv\".format(\"_vs_\".join(models)),\"w\") as f:\n",
    "        f.write(\"evaluation of the model on the full train set (division-based) on all the ablation datasets\\n\")\n",
    "        headers=['Model','ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BERTScore', 'BLEURT','Fact',\"Average\"]\n",
    "        f.write(\",\".join(headers)+\"\\n\")\n",
    "        for dataset in [\"test1\",\"test2\",\"test3\"]:\n",
    "            f.write(\"{},\".format(dataset))\n",
    "            model_map={}\n",
    "            #read_data\n",
    "            for model in models:\n",
    "                #dataset,dataset,\n",
    "                outfile='../results/bart-large-xsum-samsum_ablation_{}_{}_train_ori_division_combined.csv.json'.format(dataset,model)\n",
    "                \n",
    "                if not os.path.isfile(outfile):\n",
    "                    outfile='../results/bart-large-xsum-samsum_ablation_{}_{}_train_ori_division_combined.csv.json'.format(dataset,model)\n",
    "                model_map[model+\"-ori\"]=outfile\n",
    "                outfile='../results/bart-large-xsum-samsum_ablation_SOAP_note_train_{}_{}_{}.csv.json'.format(train_set,dataset,model)\n",
    "                model_map[model+\"-\"+train_set]=outfile\n",
    "\n",
    "            for key in model_map:\n",
    "                    row=[key]\n",
    "                    if os.path.isfile(model_map[key]):\n",
    "                        result=json.loads(open(model_map[key]).read())[\"ALL\"]\n",
    "                        for metric in ['rouge1', 'rouge2', 'rougeLsum', 'bertscore-f1', 'bleurt','umls']:\n",
    "                            row.append(float(result[metric]))\n",
    "                        row.append(((sum(row[1:4])/3+sum(row[4:7])))/4)\n",
    "                        row=[row[0]]+[\"{:.2f}\".format(round(r*100,2)) for r in row[1:]]\n",
    "                    else:\n",
    "                        row=row+[\"\"]*6\n",
    "                        print(model_map[key])\n",
    "                    f.write(\",\".join(row)+\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tabulate import tabulate\n",
    "from texttable import Texttable\n",
    "from latextable import draw_latex\n",
    "import json\n",
    "import os\n",
    "\n",
    "files=glob(\"../results/*.json\")\n",
    "# read a particular example\n",
    "value_key=\"cc-Left knee pain(support:1)\"\n",
    "\n",
    "dataset=\"valid\"\n",
    "model_map={\n",
    "        \"longest spearker turn\":'../results/longest_speaker_turn_{}.csv.json'.format(dataset),\n",
    "        \"longest doctor turn\":'../results/longest_doctor_turn_{}.csv.json'.format(dataset),\n",
    "        \"12 speaker turns\":'../results/12_speaker_turns_{}.csv.json'.format(dataset),\n",
    "        \"12 doctor turns\": '../results/12_doctor_turns_{}.csv.json'.format(dataset),\n",
    "        \"transcript\":\"../results/transcript_{}.csv.json\".format(dataset),\n",
    "        \"train_UMLS\":\"../results/UMLS_similarity_{}.csv.json\".format(dataset),\n",
    "        \"train_sent\":'../results/spacy_similarity_{}.csv.json'.format(dataset),\n",
    "    }\n",
    "\n",
    "for model in [\"BART_large\",\"bart-large-xsum-samsum\",\"BioBART\",\"LED_1024\",\"LED_pubmed_1024\"]:\n",
    "        outfile='../results/{}_{}_full_ori.csv.json'.format(model,dataset)\n",
    "        if outfile not in files:\n",
    "            outfile=[file for file in files if \"{}_{}_full_ori_prediction\".format(model,dataset) in file]\n",
    "            outfile.sort()\n",
    "            outfile=outfile[-1]\n",
    "        key=model.replace(\"_1024\",\"\").replace(\"bart-large\",\"BART\").replace(\"_large\",\"\").replace(\"-xsum-samsum\",\"+FT_$_{\\mathrm{SAMSum}}$\").replace(\"_pubmed\",\"+FT$_{\\mathrm{PubMed}}$\")\n",
    "        #baseline\n",
    "        model_map[key]=outfile\n",
    "        \n",
    "        outfile=[file for file in files if model in file and \"{}_{}_ori_division_combined\".format(model,dataset) in file]\n",
    "        model_map[key+\" (Division)\"]=outfile[-1]\n",
    "        \n",
    "with open(\"../tables/example.csv\",\"w\") as f:\n",
    "        headers=['Model','ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BERTScore', 'BLEURT','Fact',\"average\"]\n",
    "        f.write(\",\".join(headers)+\"\\n\")\n",
    "        table = Texttable()\n",
    "        table.set_cols_align([\"c\"] * len(headers))\n",
    "        table.set_deco(Texttable.HEADER)\n",
    "        table.add_row(headers)\n",
    "        for key in model_map:\n",
    "            if key in [\"BART\",\"LED\"]:\n",
    "                f.write(\"{}-based\\n\".format(key))\n",
    "            elif key==\"longest spearker turn\":\n",
    "                f.write(\"Transcript-based\\n\")\n",
    "            elif key==\"train_UMLS\":\n",
    "                f.write(\"Retrieval-based\\n\")\n",
    "            row=[key]\n",
    "            if os.path.isfile(model_map[key]):\n",
    "                result=json.loads(open(model_map[key]).read())[value_key]\n",
    "                for metric in ['rouge1', 'rouge2', 'rougeLsum', 'bertscore-f1', 'bleurt','umls']:\n",
    "                    row.append(float(result[metric]))\n",
    "                row.append(((sum(row[1:4])/3+sum(row[4:7])))/4)\n",
    "                row=[row[0]]+[\"{:.2f}\".format(round(r*100,2)) for r in row[1:]]\n",
    "            else:\n",
    "                row=row+[\"NA\"]*7\n",
    "            table.add_row(row)\n",
    "            f.write(\",\".join(row)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print txt document\n",
    "import pandas as pd\n",
    "source_df=pd.read_csv(\"/home/velvinfu/data/CLEF/clef2023_v5/challenge_data/valid.csv\")\n",
    "\n",
    "text_dic={}\n",
    "text_dic[\"true\"]=source_df[\"note\"][12]\n",
    "text_dic[\"transcript\"]=source_df[\"dialogue\"][12]\n",
    "for key in model_map:\n",
    "    pred_file=model_map[key]\n",
    "    source_path=\"/home/velvinfu/code/seq2seq/predictions/{}\".format(pred_file.replace(\".json\",\"\").split(\"/\")[-1])\n",
    "    df=pd.read_csv(source_path)#[\"note\"]\n",
    "    text_dic[key]=df[\"note\"].to_list()[12]\n",
    "\n",
    "for key in text_dic:\n",
    "    with open(\"../example_predictions - valid_D2N080/{}.txt\".format(key),\"w\") as f:\n",
    "        f.write(text_dic[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# print all umls conccepts\n",
    "#define the fact-based extractor\n",
    "quickumls_fp = \"/home/velvinfu/data/2022AA/des/\"\n",
    "umls_zip= \"/home/velvinfu/data/2022AA/umls-2022AA-metathesaurus.zip\"\n",
    "PYM_DIR=\"/home/velvinfu/code_reproduction/data_augmentation/pym.sqlite3\" #PyMedTermino\n",
    "#the window size for transitioning\n",
    "WINDOW_SIZE=5\n",
    "COUNT_THRESHOLD=50\n",
    "ENCODING=\"utf-8\"\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "\n",
    "from semantics import SEMANTICS\n",
    "\n",
    "from quickumls import QuickUMLS\n",
    "matcher = QuickUMLS(quickumls_fp,window=WINDOW_SIZE,threshold=1,accepted_semtypes=SEMANTICS)\n",
    "\n",
    "\n",
    "def add_umls(text):\n",
    "    matches=matcher.match(text, ignore_syntax=True)\n",
    "    UMLS_set=[]\n",
    "    for match in matches:\n",
    "        #print([m['semtypes'] for m in match])\n",
    "        UMLS_set.append([match[0]['start'],match[0]['end'],\", \".join(set([w for m in match for w in m['semtypes']]))])\n",
    "        #print(match)\n",
    "    UMLS_set.sort(key = lambda x: [x[0],x[1]])\n",
    "\n",
    "    result=text[:UMLS_set[0][0]]\n",
    "    for i,(s,e,type) in enumerate(UMLS_set):\n",
    "        result+=\"<{}>\".format(text[s:e])\n",
    "        if i<len(UMLS_set)-1:\n",
    "            result+=text[e:UMLS_set[i+1][0]]\n",
    "        else:\n",
    "            result+=text[e:]\n",
    "    return result\n",
    "\n",
    "for file in glob(\"../example_predictions - valid_D2N080/*.txt\"):\n",
    "    text=open(file).read()\n",
    "    with open(file,\"w\") as f:\n",
    "        f.write(add_umls(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
