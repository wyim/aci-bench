{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process\n",
    "\n",
    "This code creates the evaluation bash script that calls the evaluation for each test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the model logs to save space\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "for path in glob(\"experiments/*\"):\n",
    "        if os.path.isdir(path+\"/runs\"):\n",
    "            shutil.rmtree(path+\"/runs\")\n",
    "        for subpath in glob(path+\"/*\"):\n",
    "             if os.path.isdir(subpath) and \"best_model\" not in subpath:\n",
    "                shutil.rmtree(subpath)\n",
    "\n",
    "for file in glob(\"experiments/**/*.bin\"):\n",
    "    if \"best_model\" not in file:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions from division-based approaches\n",
    "import json\n",
    "\n",
    "sec_map={\n",
    "    \"subjective\": \"chief complaint :\", \n",
    "    \"objective_exam\":\"physical examination :\", \n",
    "    \"objective_results\": \"results :\",\n",
    "    \"assessment_and_plan\": \"ASSESSMENT AND PLAN\"    \n",
    "}\n",
    "\n",
    "division_types=[\"subjective\",\"objective_exam\", \"objective_results\",\"assessment_and_plan\"]\n",
    "\n",
    "for fine_tune in [\"\",\"finetune3_\"]:\n",
    "    for trainset in [\"virtscribe_asr\",\"aci_asrcorr\"]:#\n",
    "        for testset in [\"test1\",\"test2\",\"test3\"]:\n",
    "            for testset2 in [\"aci_asr\",\"aci_asrcorr\",\"virtscribe_asr\",\"virtscribe_humantrans\"]:\n",
    "                model=\"bart-large-xsum-samsum\"\n",
    "                #\n",
    "                out_dir=f\"experiments/{model}_{testset}_{testset2}_division_combined_train_{fine_tune}{trainset}\"\n",
    "                if not os.path.isdir(out_dir):\n",
    "                    os.mkdir(out_dir)\n",
    "\n",
    "                pred_dir=f\"../data/scr_experiment_data_json/{testset}_{testset2}.json\"\n",
    "                \n",
    "                old_pred=json.loads(open(pred_dir).read())['data']\n",
    "                pred=[]\n",
    "\n",
    "                for p in old_pred:\n",
    "                        pred.append({\n",
    "                            \"source\":p[\"src\"],\n",
    "                            \"true\":p[\"tgt\"],\n",
    "                            \"pred\":\"\"\n",
    "                        })\n",
    "\n",
    "                for sec in division_types: \n",
    "                    #For bart-based models\n",
    "                    #ablation_bart-large-xsum-samsum_${testset}_${testset2}_${section}_train_${trainset}\n",
    "                    source_dir=glob(f\"experiments/ablation_{model}_{testset}_{testset2}_{sec}_train_{fine_tune}{trainset}/prediction_{testset}_{testset2}_{sec}.json\")\n",
    "                    assert len(source_dir)==1,source_dir\n",
    "                    source_dir=source_dir[-1]\n",
    "                    section=json.loads(open(source_dir).read())\n",
    "                    assert len(section)==len(pred), [len(section),len(pred)]\n",
    "                    for i,p in enumerate(pred):\n",
    "                        pred[i][\"pred\"]+=\"\\n\"+section[i][\"pred\"]\n",
    "                    \n",
    "                with open(out_dir+\"/prediction.json\",\"w\",encoding=\"utf-8\") as f :\n",
    "                    json.dump(pred,f,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the result\n",
    "\n",
    "1. extract predictions from the baseline/experiment folder, reformat into csv style into the predictions folder.\n",
    "2. generate the bash script for running evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "RESOURCE_DIR = '../resource/'\n",
    "\n",
    "CHALLENGE_DATA_DIR = DATA_DIR+'challenge_data_json/' \n",
    "SRCEXP_DATA_dir = DATA_DIR+'scr_experiment_data/'\n",
    "\n",
    "testsets = [\"clinicalnlp_taskB_test1\", \"clinicalnlp_taskC_test2\",\"clef_taskC_test3\"]\n",
    "testsets = [\"test1\", \"test2\",\"test3\"]\n",
    "PRED_DIR = \"predictions/\"\n",
    "RESULT_DIR = \"results/\"\n",
    "if not os.path.isdir(PRED_DIR):\n",
    "    os.mkdir(PRED_DIR)\n",
    "if not os.path.isdir(RESULT_DIR):\n",
    "    os.mkdir(RESULT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the reference script for the tabl\n",
    "dataset_map={}\n",
    "\n",
    "#map for the ablation study\n",
    "for testset in testsets:\n",
    "    for testset2 in [ \"aci_asrcorr\", \"aci_asr\", \"virtscribe_asr\", \"virtscribe_humantrans\" ]:\n",
    "        #{model}_{testset}_{testset2}_division_combined_train_{trainset}/prediction.json\n",
    "        dataset_map[\"{}_{}_\".format(testset,testset2)]=\"{}scr_experiment_data/{}_{}.csv\".format(DATA_DIR,testset,testset2)\n",
    "        dataset_map[\"{}_{}.\".format(testset,testset2)]=dataset_map[\"{}_{}_\".format(testset,testset2)]\n",
    "\n",
    "\n",
    "all_paths=glob(\"experiments/*\")\n",
    "all_paths=[p for p in all_paths if \"ablation\" in path]\n",
    "\n",
    "results_to_evaluate=[\"full\",\"division\"]\n",
    "\n",
    "#print(pred_files)\n",
    "with open(\"ablation_evaluation_script.sh\",\"w\") as f:\n",
    "    for path in all_paths:\n",
    "        pred_files=[file for file in glob(path+\"/*.json\") if \"prediction\" in file and \"epoch\" not in file]\n",
    "        if pred_files:\n",
    "            pred_files.sort()\n",
    "            file=pred_files[-1]\n",
    "\n",
    "            #if the result will be included in the table\n",
    "            if any([r in file for r in results_to_evaluate]):\n",
    "                for key in dataset_map:\n",
    "                    if key in file:\n",
    "                            outname=\"predictions/{}.csv\".format(path.split(\"/\")[-1])\n",
    "                            \n",
    "                            #generate prediction file\n",
    "                            pred=json.loads(open(file).read())\n",
    "                            src_df=pd.read_csv(dataset_map[key],encoding=\"utf-8\")\n",
    "                            if len(pred)==len(src_df):\n",
    "                                for ind,p in enumerate(pred):\n",
    "                                    src_df['note'][ind]=p['pred']\n",
    "                                src_df['dataset'][ind]=src_df['dataset'][ind]+\"-{}\".format(ind)\n",
    "                            else:\n",
    "                                print([file,key,\"error\"])\n",
    "                                continue\n",
    "                            \n",
    "                            src_df.to_csv(outname,index=False)\n",
    "                            f.write(\"python evaluation/evaluate_fullnote.py \\\\\\n\")\n",
    "                            f.write(dataset_map[key][3:]+\" \\\\\\n\") # ref\n",
    "                            assert os.path.isfile(dataset_map[key]), dataset_map[key]\n",
    "                            assert  os.path.isfile(outname),outname\n",
    "                            f.write(\"baselines/\"+outname+\" \\\\\\n\") # prediction\n",
    "                            \n",
    "                            meta_file=dataset_map[key].replace(\".csv\",\"_metadata.csv\")\n",
    "                            if os.path.isfile(meta_file):\n",
    "                                f.write(meta_file[3:]+\"\\n\") #write meta-data\n",
    "                            else:\n",
    "                                print(meta_file)\n",
    "                            f.write(\"\\n\\n\\n\")\n",
    "                            break  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the results to tables\n",
    "\n",
    "first, run the evaluation script through\n",
    "\n",
    "```\n",
    "bash ./baselines/ablation_evaluation_script.sh\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output to latex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASR and human\n",
    "\n",
    "abalation_begin=\"\"\"\n",
    "\\\\begin{table}[]\n",
    "\\\\centering\n",
    "\\\\begin{tabular}{ccccccc}\n",
    "\\\\hline\n",
    "\\\\textbf{\\\\begin{tabular}[c]{@{}c@{}}Test\\\\\\\\ set\\\\end{tabular}} & \\\\textbf{\\\\begin{tabular}[c]{@{}c@{}}Bart\\\\\\\\ Fine-tuning\\\\end{tabular}} & \\\\textbf{\\\\begin{tabular}[c]{@{}c@{}}Test\\\\\\\\ Split\\\\end{tabular}} & \\\\textbf{ROUGE-1} & \\\\textbf{ROUGE-2} & \\\\textbf{ROUGE-L} & \\\\textbf{Fact} \\\\\\\\ \\\\hline\n",
    "\"\"\"\n",
    "\n",
    "abalation_end=\"\"\"\n",
    "\\\\end{tabular}\n",
    "\\\\caption{Model performance on different test sets splits, comparison between \\\\textit{CATEGORY} dialogues with LABEL1 and LABEL2 transcript. The model finetuned on the train set is the BART+FT$_{\\\\mathrm{SAMSum}}$ (Division) fine-tuned with 10 epochs on the original train set, as in the baseline methods. The train + train$_{\\\\mathrm{TRAIN_LABEL}}$ model refers to the BART+FT$_{\\\\mathrm{SAMSum}}$ (Division) finetuned for 3 more epochs on the \\\\textit{CATEGORY} with TRAIN_LABEL split of the train set.}\n",
    "\\\\label{tab:ablation_}\n",
    "\\\\end{table}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tex(text,filename):\n",
    "    with open(filename,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    return\n",
    "\n",
    "result_type=\"ALL\"\n",
    "metrics=['rouge1', 'rouge2', 'rougeLsum', 'umls']\n",
    "testsets=[\"test1\",\"test2\",\"test3\"]\n",
    "trainsets=[[\"\",\"virtscribe_asr\"],[\"\",\"aci_asrcorr\"]]\n",
    "testsets2=[[\"virtscribe_asr\",\"virtscribe_humantrans\"],[\"aci_asr\",\"aci_asrcorr\"]]\n",
    "model=\"bart-large-xsum-samsum\"\n",
    "for trainset, testset2 in zip(trainsets,testsets2):\n",
    "    \n",
    "    finetune_type=trainset[1].split(\"_\")[1]\n",
    "    finetune_type=finetune_type.upper() if finetune_type==\"asr\" else finetune_type\n",
    "\n",
    "    labels=[t.split(\"_\")[1].replace(\"trans\",\"\") for t in testset2]\n",
    "    \n",
    "    outname=f\"../tables/ablation_{labels[0]}_vs_{labels[1]}.tex\"\n",
    "    \n",
    "    labels=[l.upper() if l==\"asr\" else l for l in labels ]\n",
    "    \n",
    "    text=abalation_begin\n",
    "    max_values={}\n",
    "    for testset in testsets:\n",
    "        \n",
    "\n",
    "        text+=\"\\\\multirow{4}{*}{\"+str(testset[-1])+\"}\"\n",
    "        \n",
    "        for test_type,label in zip(testset2,labels):\n",
    "            for train_type in trainset:\n",
    "                if not train_type:\n",
    "                    filename=f\"../results/{model}_{testset}_{test_type}_division_combined_train_{trainset[-1]}.json\"\n",
    "                    text+=\"&train\" \n",
    "                else:\n",
    "                    filename=f\"../results/{model}_{testset}_{test_type}_division_combined_train_finetune3_{trainset[-1]}.json\"\n",
    "                    text+=\"&+train$_{\\\\mathrm{\"+finetune_type+\"}}$\"\n",
    "                text+=f\"&{label}&\"\n",
    "\n",
    "                if os.path.isfile(filename):\n",
    "                    result=json.loads(open(filename).read())[result_type]\n",
    "                    row=[]\n",
    "                    for metric in metrics:\n",
    "                        row.append(float(result[metric]))\n",
    "                        max_values[metric+testset]=max(max_values.get(metric+testset,row[-1]),row[-1])\n",
    "                    row=[\"{:.2f}\".format(r*100) for r in row]\n",
    "                else:\n",
    "                    row=[\"NA\"]*4\n",
    "                text+=\"&\".join(row)+\"\\\\\\\\ \\n\"\n",
    "\n",
    "        text+=\"\\\\cline{1-3}\" if testset!=testsets[-1] else \"\\\\hline\"\n",
    "    text+=abalation_end\n",
    "\n",
    "    # highlight the max values\n",
    "    for metric in max_values:\n",
    "            number=\"{:.2f}\".format(round(max_values[metric]*100,2))\n",
    "            if text.count(number)==1:\n",
    "                text=text.replace(number,\"\\\\textbf{\"+number+\"}\")\n",
    "            else:\n",
    "                print([text.count(number),metric])\n",
    "\n",
    "    text=text.replace(\"CATEGORY\",trainset[1].split(\"_\")[0])\n",
    "    text=text.replace(\"LABEL1\",labels[0])\n",
    "    text=text.replace(\"LABEL2\",labels[1])\n",
    "    text=text.replace(\"TRAIN_LABEL\",finetune_type)\n",
    "    text=text.replace(\"asrcorr\",\"ASRcorr\")\n",
    "    text=text.replace(\"tab:ablation_\",f\"tab:ablation_{labels[0]}_{labels[1]}\".lower())\n",
    "    write_tex(text,outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1test3': 0.5312651200192207,\n",
       " 'rouge2test3': 0.23528875463861948,\n",
       " 'rougeLsumtest3': 0.4772540734469096,\n",
       " 'umlstest3': 0.46379720063786994}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/bart-large-xsum-samsum_test3_aci_asrcorr_division_combined_train_finetune3_aci_asrcorr.json'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read prediction example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=\"/home/velvinfu/code/aci-demo-benchmark-private-main/baselines/experiments/2_bart-large-xsum-samsum_clinicalnlp_taskC_test2_full/prediction_clinicalnlp_taskC_test2_full.json\"\n",
    "file2=\"/home/velvinfu/code/clef2023-internal/predictions/bart-large-xsum-samsum_test2_full_ori.json\"\n",
    "file3=\"/home/velvinfu/code/aci-demo-benchmark-private-main/baselines/experiments/bart-large-xsum-samsum_clinicalnlp_taskC_test2_full/prediction_clinicalnlp_taskC_test2_full.json\"\n",
    "\n",
    "import json\n",
    "result1=json.loads(open(file1).read())[0][\"pred\"]\n",
    "result2=json.loads(open(file2).read())[0][\"pred\"]\n",
    "result3=json.loads(open(file3).read())[0][\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1==result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHIEF COMPLAINT\\n\\nOsteoarthritis follow-up.\\n\\nHISTORY OF PRESENT ILLNESS\\n\\nThe patient is a 49-year-old female who presents for follow up of her chronic problems. She is a right-handed female who reports she has been experiencing pain in her right elbow and right hand with typing. She has a history of gout and psoriasis. The last episode of her last episode was about 3 months ago. She denies any other issues. She reports pain with flexion and extension of the right arm and pain with pronation and supination. She also reports numbness and tingling in her hands when she is typing for long periods of time. She states she tries to shake her arms a little bit to help relieve the pain. The patient has had edema and inflammation of her right olecranon bursa and there is some tenderness and an effusion right there. When she turns her arm, that hurts a bit too. She experiences pain when she flexes and straightens her arm. Her right toe has some inflammation of the toe, but she has not seen a flare-up since the last episode. She notes that the medication she'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHIEF COMPLAINT\\n\\nOsteoarthritis follow-up.\\n\\nHISTORY OF PRESENT ILLNESS\\n\\nCarolyn is a 49-year-old female who is here for follow up of her chronic problems. She is a right-handed female who has a history of gout and psoriasis. The last episode of her last episode was about 3 months ago. She reports pain with flexion and extension of the right arm and pain with pronation and supination. She has pain with palpation of the olecranon bursa. She experiences numbness and tingling in her hands when she is typing for long periods of time. She tries to shake her arms a little bit to relieve the pain. The right elbow does bother her more than the other, but she is primarily typing all day versus writing. She denies any other joint pain. She had some inflammation of her right toe, but the medication she was given for that has controlled it and she has not seen a flare-up since the last episode. She also had an autoimmune response to clobetasol for her scalp, which has been doing well.\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHIEF COMPLAINT\\n\\nThe patient is a 49-year-old female who is here for follow-up of her chronic problems.\\n\\nOsteoarthritis has been flaring up a little bit lately. The patient reports pain with extension of the right arm and pain with pronation and supination. She also reports pain-to- palpation of the olecranon bursa. She has had a history of gout and has not seen a flare-up since the last episode 3 months ago. She reports that the medication she was given for gout has been effective in controlling her symptoms. She states that her psoriasis has been under control for the last 3 months. She does not appreciate any cervical lymphadenopathy. Her heart rate is a nice regular rate and rhythm, and her lungs sound clear. She experiences numbing or tingling in her hands when typing for long periods of time.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_acidemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
